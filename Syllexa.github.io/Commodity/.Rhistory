library(XML) #Loading XML package
library(htmltools)
setwd("C:\Users\Vishu\Documents\GitHub\Syllexa\Syllexa.github.io\Commodity")
setwd("C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Commodity")
wd()
getwd()
url<-"http://www.goldpriceindia.com/gold-price-history.php"
url1<-"http://www.goldpriceindia.com/"
doc <- htmlParse(url) #Parses an HTML file and form a readable R file
links <- xpathSApply(doc, "//a/@href")
Links<-links[grep("2015",links,ignore.case = T)]
Links<- Links[c(-1,-2)]
Month_URL<- paste(url1,Links,sep = "")
Gold_Date<- list()
Gold_Data<- list()
for(a in seq(Month_URL)){
url<- Month_URL[a]
doc <- readLines(url)
Month_Data<-list()
Month_Date<- list()
for(i in seq(length(grep("his-dt-G-hd",doc)))){
Month_Date[i]<-strsplit(doc[grep("his-dt-G-hd",doc)],"his-dt-G-hd")[[i]][2]
Month_Date[i]<-gsub("\" colspan=\"4\">|</td>","",Month_Date[i])}
for(i in seq(length(grep("his-eod-2",doc)))){
Month_Data[i]<- strsplit(doc[grep("his-eod-2",doc)],"his-eod-2")[[i]][2]
Month_Data[i]<- gsub("\\\">|</td>","",Month_Data[i])}
if(a==1){Gold_Date=Month_Date}
else(Gold_Date<- c(Gold_Date,Month_Date))
if(a==1){Gold_Data=Month_Data}
else(Gold_Data<- c(Gold_Data,Month_Data))
print(a)
}
Gold_Data<- unlist(Gold_Data)
Gold_Date<- unlist(Gold_Date)
Gold_Date<- as.Date(gsub("Gold Price on ","",Gold_Date),"%d %B %Y")
Gold_Data<- as.numeric(gsub(",","",Gold_Data))
Gold<- as.data.frame(x = Gold_Date)
colnames(Gold)<- "Date"
Gold$Data<- Gold_Data
Oil<- read.xls("http://www.eia.gov/dnav/pet/hist_xls/RBRTEd.xls",sheet = 2,pattern = "Date",verbose = T)
Oil$Date<- as.Date(as.character(Oil$Date),format = "%b %d, %Y")
colnames(Oil)[2]<- "Prices"
Oil<- subset(Oil,Oil$Prices!=".")
Oil<- Oil[format(Oil$Date,"%Y")==2015,]
Gold<- Gold[order(Gold$Date),]
Gold<- Gold[Gold$Date %in% Oil$Date,]
Commodity<- cbind(Gold,Oil)
library(xts)
Oil<- read.xls("http://www.eia.gov/dnav/pet/hist_xls/RBRTEd.xls",sheet = 2,pattern = "Date",verbose = T)
library(gdata)
Oil<- read.xls("http://www.eia.gov/dnav/pet/hist_xls/RBRTEd.xls",sheet = 2,pattern = "Date",verbose = T)
Oil$Date<- as.Date(as.character(Oil$Date),format = "%b %d, %Y")
colnames(Oil)
colnames(Oil)[2]<- "Prices"
View(Oil)
Oil<- subset(Oil,Oil$Prices!=".")
format(Sys.Date(),"%Y")
Oil[format(Oil$Date,"%Y")==format(Sys.Date(),"%Y"),]
Oil<- Oil[format(Oil$Date,"%Y")==format(Sys.Date(),"%Y"),]
Gold[order(Gold$Date),]
Gold<- Gold[order(Gold$Date),]
Gold[Gold$Date %in% Oil$Date,]
Gold<- Gold[Gold$Date %in% Oil$Date,]
Commodity<- cbind(Gold,Oil)
Commodity[,!(duplicated(colnames(Commodity)))]
colnames(Commodity)
Commodity<- Commodity[,!(duplicated(colnames(Commodity)))]
colnames(Commodity)
colnames(Commodity) <- c("Date","Gold","Oil")
colnames(Commodity)
write.csv(Commodity,"data.csv")
Function<-dget(file = "C:\\Users\\Vishu\\OneDrive\\Data Scraping\\NSE-BSE Historical Prices\\GoogFin.R")
USD_INR<- Function(ticker = "USDINR",exchange = "",TimeFrame = "1Y")
colnames(USD_INR)[5]<- "USD_INR"
Pound_INR<- Function(ticker = "GBPINR",exchange = "",TimeFrame = "1Y")
colnames(Pound_INR)[5]<-"Pound_INR"
Euro_INR<-Function(ticker = "EURINR",exchange = "",TimeFrame = "1Y")
colnames(Euro_INR)[5]<-"Euro_INR"
Currency<- cbind(USD_INR,Pound_INR,Euro_INR)
Currency<- Currency[,c("Date","USD_INR","Pound_INR","Euro_INR")]
View(Currency)
write(Currency,"C:\Users\Vishu\Documents\GitHub\Syllexa\Syllexa.github.io\Currency\Currency.csv")
write(Currency,"C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Currency\\Currency.csv")
write.csv(Currency,"C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Currency\\Currency.csv")
library(XML)
rm(list=ls())
library(XML)
library(XML)
investing_url<-"http://in.investing.com"
#Econoomic calender url
link<- "http://in.investing.com/economic-calendar/?"
if(time_Frame=="nextWeek"){
DateFrom<- Sys.Date() +3
DateTo<- Sys.Date() + 9}
if(time_Frame=="today"){
DateFrom<- Sys.Date()
DateTo<- Sys.Date()}
if(time_Frame=="tomorrow"){
DateFrom<- Sys.Date()+1
DateTo<- Sys.Date()+1}
if(time_Frame=="yesterday"){
DateFrom<- Sys.Date()-1
DateTo<- Sys.Date()-1}
if(time_Frame=="thisWeek"){
DateFrom<- (Sys.Date()-c(6:0))[format((Sys.Date()-c(6:0)),"%w")=="1"]
DateTo<- Sys.Date()}
Paster="&timeZone=23&quotes_search_text=&country%5B%5D=25&country%5B%5D=32&country%5B%5D=6&country%5B%5D=37&country%5B%5D=72&country%5B%5D=22&country%5B%5D=17&country%5B%5D=39&country%5B%5D=14&country%5B%5D=10&country%5B%5D=35&country%5B%5D=43&country%5B%5D=56&country%5B%5D=36&country%5B%5D=110&country%5B%5D=11&country%5B%5D=26&country%5B%5D=12&country%5B%5D=4&country%5B%5D=5&timeFilter=timeRemain&timeFrame="
Paster<- paste("dateFrom","=",DateFrom,"&","dateTo",'=',DateTo,Paster,time_Frame,sep = "")
link<- paste(link,Paster,sep = "")
doc <- readLines(url(link))
#links <- doc[grep("href",doc,ignore.case = T)]
News_Line<-grep("Click to View",doc,ignore.case = T)
day_line<- grep("theDay",doc)
NEWS<-doc[News_Line+1] #Finding all xls files
day<- doc[day_line]
for(a in seq(day)){
day[a]<- strsplit(day[a],">")[[1]][2]}
day<- gsub("</td","",day)
NEWS<- as.data.frame(NEWS)
NEWS$Day<- 0
for(i in seq(day_line)){
for(a in seq(News_Line)){
if(day_line[i]<News_Line[a]){
NEWS$Day[a]<- day[i]}
}
}
NEWS$NEWS<- as.character(NEWS$NEWS)
NEWS$Country<- doc[News_Line-2]
NEWS$News<-0
NEWS$Actual<- doc[grep("eventactual",doc,ignore.case = T)]
NEWS$Projection<- doc[grep("eventforecast",doc,ignore.case = T)]
NEWS$Previous<- doc[grep("eventprevious",doc,ignore.case = T)]
NEWS$Volatilty<- doc[News_Line-1]
for(a in seq(nrow(NEWS))){
NEWS$NEWS[a]<-strsplit(strsplit(x = NEWS$NEWS[a],split = "\t\t\t\t")[[1]][2],"</a>")[[1]][1]}
NEWS$News<- gsub("(^[[:space:]]+|[[:space:]]+$)", "", NEWS$NEWS)
for(a in seq(nrow(NEWS))){
NEWS$Country[a]<-strsplit(NEWS$Country[a],split = "class|tittle")[[1]][2]
NEWS$Projection[a]<-strsplit(NEWS$Projection[a],split = "class|tittle")[[1]][2]
NEWS$Actual[a]<-strsplit(NEWS$Actual[a],split = "class|tittle")[[1]][2]
NEWS$Previous[a]<-strsplit(NEWS$Previous[a],split = "class|tittle")[[1]][2]
NEWS$Volatilty[a]<-strsplit(NEWS$Volatilty[a],split = "class|tittle")[[1]][2]}
NEWS$Country<- gsub("^=\"","",NEWS$Country)
NEWS$Country<- gsub("\"","",NEWS$Country)
NEWS$Country<- gsub("left flagCur noWrap><span title=","",NEWS$Country)
###############
NEWS$Projection<- gsub("^=\"","",NEWS$Projection)
NEWS$Projection<- gsub("\"","",NEWS$Projection)
for(a in seq(nrow(NEWS))){
NEWS$Projection[a]<- strsplit(NEWS$Projection[a],">")[[1]][2]}
NEWS$Projection<- gsub("</td","",NEWS$Projection)
NEWS$Projection<- gsub("&nbsp;","No Data",NEWS$Projection)
######
NEWS$Actual<- gsub("^=\"","",NEWS$Actual)
NEWS$Actual<- gsub("\"","",NEWS$Actual)
for(a in seq(nrow(NEWS))){
NEWS$Actual[a]<- strsplit(NEWS$Actual[a],">")[[1]][2]}
NEWS$Actual<- gsub("</td","",NEWS$Actual)
NEWS$Actual<- gsub("&nbsp;","No Data",NEWS$Actual)
################3
NEWS$Previous<- gsub("^=\"","",NEWS$Previous)
NEWS$Previous<- gsub("\"","",NEWS$Previous)
for(a in seq(nrow(NEWS))){
NEWS$Previous[a]<- strsplit(NEWS$Previous[a],">")[[1]][2]}
NEWS$Previous<- gsub("</td","",NEWS$Previous)
NEWS$Previous<- gsub("&nbsp;","No Data",NEWS$Previous)
############################3
for(a in seq(nrow(NEWS))){
NEWS$Volatilty[a]<- strsplit(NEWS$Volatilty[a],"title")[[1]][2]}
NEWS$Volatilty<-gsub("^=\"","",NEWS$Volatilty)
for(a in seq(nrow(NEWS))){
NEWS$Volatilty[a]<- strsplit(NEWS$Volatilty[a],"\"")[[1]][1]}
NEWS$Link<- doc[News_Line]
for(a in seq(nrow(NEWS))){
NEWS$Link[a]<- strsplit(NEWS$Link[a],split = "href")[[1]][2]}
NEWS$Link<-gsub("^=\"","",NEWS$Link)
NEWS$Link<- gsub("target=\"_blank\">","",NEWS$Link)
NEWS$Link<-gsub("\"","",NEWS$Link)
NEWS$Link<-gsub("(^[[:space:]]+|[[:space:]]+$)", "", NEWS$Link)
NEWS$Link<- paste(investing_url,NEWS$Link,sep = "")
NEWS<- NEWS[!duplicated(NEWS),]
#for(a in seq(nrow(NEWS))){
#url<- readLines(url(NEWS$Link[a]))
#NEWS$Detail[a]<- url[grep("overviewBox",url,ignore.case = T)+1]
#NEWS$Detail[a]<- strsplit(NEWS$Detail[a],split = "left")[[1]][2]
#NEWS$Detail[a]<- gsub("\"","",NEWS$Detail[a])
#NEWS$Detail[a]<- gsub("<BR>","",gsub("/","",NEWS$Detail[a]))
#NEWS$Detail[a]<- gsub("<div>","",NEWS$Detail[a])
#NEWS$Detail[a]<- gsub("^>","",NEWS$Detail[a])
#print(a)}
NEWS$NEWS<-NULL
NEWS$Link<- NULL
NEWS<- subset(NEWS,NEWS$Volatilty!="Low Volatility Expected")
rm(list=ls())
time_Frame="nextWeek"
library(XML)
#Main Website url
investing_url<-"http://in.investing.com"
#Econoomic calender url
link<- "http://in.investing.com/economic-calendar/?"
if(time_Frame=="nextWeek"){
DateFrom<- Sys.Date() +3
DateTo<- Sys.Date() + 9}
if(time_Frame=="today"){
DateFrom<- Sys.Date()
DateTo<- Sys.Date()}
if(time_Frame=="tomorrow"){
DateFrom<- Sys.Date()+1
DateTo<- Sys.Date()+1}
if(time_Frame=="yesterday"){
DateFrom<- Sys.Date()-1
DateTo<- Sys.Date()-1}
if(time_Frame=="thisWeek"){
DateFrom<- (Sys.Date()-c(6:0))[format((Sys.Date()-c(6:0)),"%w")=="1"]
DateTo<- Sys.Date()}
Paster="&timeZone=23&quotes_search_text=&country%5B%5D=25&country%5B%5D=32&country%5B%5D=6&country%5B%5D=37&country%5B%5D=72&country%5B%5D=22&country%5B%5D=17&country%5B%5D=39&country%5B%5D=14&country%5B%5D=10&country%5B%5D=35&country%5B%5D=43&country%5B%5D=56&country%5B%5D=36&country%5B%5D=110&country%5B%5D=11&country%5B%5D=26&country%5B%5D=12&country%5B%5D=4&country%5B%5D=5&timeFilter=timeRemain&timeFrame="
Paster<- paste("dateFrom","=",DateFrom,"&","dateTo",'=',DateTo,Paster,time_Frame,sep = "")
link<- paste(link,Paster,sep = "")
doc <- readLines(url(link))
#links <- doc[grep("href",doc,ignore.case = T)]
News_Line<-grep("Click to View",doc,ignore.case = T)
day_line<- grep("theDay",doc)
NEWS<-doc[News_Line+1] #Finding all xls files
day<- doc[day_line]
for(a in seq(day)){
day[a]<- strsplit(day[a],">")[[1]][2]}
day<- gsub("</td","",day)
NEWS<- as.data.frame(NEWS)
NEWS$Day<- 0
for(i in seq(day_line)){
for(a in seq(News_Line)){
if(day_line[i]<News_Line[a]){
NEWS$Day[a]<- day[i]}
}
}
NEWS$NEWS<- as.character(NEWS$NEWS)
NEWS$Country<- doc[News_Line-2]
NEWS$News<-0
NEWS$Actual<- doc[grep("eventactual",doc,ignore.case = T)]
NEWS$Projection<- doc[grep("eventforecast",doc,ignore.case = T)]
NEWS$Previous<- doc[grep("eventprevious",doc,ignore.case = T)]
NEWS$Volatilty<- doc[News_Line-1]
for(a in seq(nrow(NEWS))){
NEWS$NEWS[a]<-strsplit(strsplit(x = NEWS$NEWS[a],split = "\t\t\t\t")[[1]][2],"</a>")[[1]][1]}
NEWS$News<- gsub("(^[[:space:]]+|[[:space:]]+$)", "", NEWS$NEWS)
for(a in seq(nrow(NEWS))){
NEWS$Country[a]<-strsplit(NEWS$Country[a],split = "class|tittle")[[1]][2]
NEWS$Projection[a]<-strsplit(NEWS$Projection[a],split = "class|tittle")[[1]][2]
NEWS$Actual[a]<-strsplit(NEWS$Actual[a],split = "class|tittle")[[1]][2]
NEWS$Previous[a]<-strsplit(NEWS$Previous[a],split = "class|tittle")[[1]][2]
NEWS$Volatilty[a]<-strsplit(NEWS$Volatilty[a],split = "class|tittle")[[1]][2]}
NEWS$Country<- gsub("^=\"","",NEWS$Country)
NEWS$Country<- gsub("\"","",NEWS$Country)
NEWS$Country<- gsub("left flagCur noWrap><span title=","",NEWS$Country)
###############
NEWS$Projection<- gsub("^=\"","",NEWS$Projection)
NEWS$Projection<- gsub("\"","",NEWS$Projection)
for(a in seq(nrow(NEWS))){
NEWS$Projection[a]<- strsplit(NEWS$Projection[a],">")[[1]][2]}
NEWS$Projection<- gsub("</td","",NEWS$Projection)
NEWS$Projection<- gsub("&nbsp;","No Data",NEWS$Projection)
######
NEWS$Actual<- gsub("^=\"","",NEWS$Actual)
NEWS$Actual<- gsub("\"","",NEWS$Actual)
for(a in seq(nrow(NEWS))){
NEWS$Actual[a]<- strsplit(NEWS$Actual[a],">")[[1]][2]}
NEWS$Actual<- gsub("</td","",NEWS$Actual)
NEWS$Actual<- gsub("&nbsp;","No Data",NEWS$Actual)
################3
NEWS$Previous<- gsub("^=\"","",NEWS$Previous)
NEWS$Previous<- gsub("\"","",NEWS$Previous)
for(a in seq(nrow(NEWS))){
NEWS$Previous[a]<- strsplit(NEWS$Previous[a],">")[[1]][2]}
NEWS$Previous<- gsub("</td","",NEWS$Previous)
NEWS$Previous<- gsub("&nbsp;","No Data",NEWS$Previous)
############################3
for(a in seq(nrow(NEWS))){
NEWS$Volatilty[a]<- strsplit(NEWS$Volatilty[a],"title")[[1]][2]}
NEWS$Volatilty<-gsub("^=\"","",NEWS$Volatilty)
for(a in seq(nrow(NEWS))){
NEWS$Volatilty[a]<- strsplit(NEWS$Volatilty[a],"\"")[[1]][1]}
NEWS$Link<- doc[News_Line]
for(a in seq(nrow(NEWS))){
NEWS$Link[a]<- strsplit(NEWS$Link[a],split = "href")[[1]][2]}
NEWS$Link<-gsub("^=\"","",NEWS$Link)
NEWS$Link<- gsub("target=\"_blank\">","",NEWS$Link)
NEWS$Link<-gsub("\"","",NEWS$Link)
NEWS$Link<-gsub("(^[[:space:]]+|[[:space:]]+$)", "", NEWS$Link)
NEWS$Link<- paste(investing_url,NEWS$Link,sep = "")
NEWS<- NEWS[!duplicated(NEWS),]
#for(a in seq(nrow(NEWS))){
#url<- readLines(url(NEWS$Link[a]))
#NEWS$Detail[a]<- url[grep("overviewBox",url,ignore.case = T)+1]
#NEWS$Detail[a]<- strsplit(NEWS$Detail[a],split = "left")[[1]][2]
#NEWS$Detail[a]<- gsub("\"","",NEWS$Detail[a])
#NEWS$Detail[a]<- gsub("<BR>","",gsub("/","",NEWS$Detail[a]))
#NEWS$Detail[a]<- gsub("<div>","",NEWS$Detail[a])
#NEWS$Detail[a]<- gsub("^>","",NEWS$Detail[a])
#print(a)}
NEWS$NEWS<-NULL
NEWS$Link<- NULL
NEWS<- subset(NEWS,NEWS$Volatilty!="Low Volatility Expected")
name<- paste("Economic Calender",Sys.Date(),sep = " ")
name<- paste(name,".csv",sep = "")
Week<- paste(format(DateFrom,"%d"),format(DateTo,"%d %b"),sep = "-")
Economic_Calender<- paste("Economic Calenedar",Week,sep = " for ")
name
name<- paste("Economic Calender",".csv",sep = "")
name
paste(format(DateFrom,"%d"),format(DateTo,"%d %b"),sep = "-")
name<- paste("C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Economic Calendar","Economic Calender",".csv",sep ="")
write.csv(NEWS,name)
name
name<- paste("C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Economic Calendar","Economic Calender",sep ="//")
name<- paste(name,".csv",sep = "")
write.csv(NEWS,name)
library(XML)
investing_url<-"http://profit.ndtv.com/market/stocks-gainers/nifty_weekly"
doc <- readLines(url(investing_url))
links <- grep("txt-right v-align",doc,ignore.case = T)
Stock<- doc[links-1]
for(a in seq(Stock)){
Stock[a]<- strsplit(Stock[a],"\">")[[1]][2]}
Stock<- gsub("</a></td>","",Stock)
Change<- doc[links+5]
for(a in seq(Change)){
Change[a]<- strsplit(Change[a],"\">")[[1]][3]}
Change<- gsub("</span></td>","",Change)
Weekly_Gainer<- as.data.frame(matrix(0,length(Change),0))
Weekly_Gainer$Stock<- Stock
Weekly_Gainer$Change<- Change
paste("C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Weekly Gainer","data.csv",sep = "//")
name<-paste("C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Weekly Gainer","data.csv",sep = "\\")
ame
name
write.csv(Weekly_Gainer,name)
rm(list=ls())
Stock<-dget(file = "https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/GoogFin.R")
dget(file = "C:\\Users\\Vishu\\OneDrive\\Data Scraping\\NSE-BSE Historical Prices\\GoogFin.R")
Nifty<- Stock(TimeFrame = "1Y")
Nifty$Change<- ROC(Nifty$Close)
Nifty$Name<-"Nifty"
colnames(Nifty)[5]<-"Nifty"
Sensex<- Stock(ticker = "SENSEX",exchange = "INDEXBOM",TimeFrame = "1Y")
Sensex$Return<- ROC(Sensex$Close)
colnames(Sensex)[5]<- "Sensex"
Data<- cbind(Nifty,Sensex)
Data<- Data[,c("Date","Nifty","Sensex")]
Stock<-dget(file = "https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/GoogFin.R")
Stock<-dget(file = "C:\\Users\\Vishu\\OneDrive\\Data Scraping\\NSE-BSE Historical Prices\\GoogFin.R")
Nifty<- Stock(TimeFrame = "1Y")
Nifty$Change<- ROC(Nifty$Close)
Nifty$Name<-"Nifty"
colnames(Nifty)[5]<-"Nifty"
Sensex<- Stock(ticker = "SENSEX",exchange = "INDEXBOM",TimeFrame = "1Y")
Sensex$Return<- ROC(Sensex$Close)
colnames(Sensex)[5]<- "Sensex"
Data<- cbind(Nifty,Sensex)
Data<- Data[,c("Date","Nifty","Sensex")]
write.csv(Data,"C:\Users\Vishu\Documents\GitHub\Syllexa\Syllexa.github.io\Market-Movement\data.csv")
write.csv(Data,"C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Market-Movement\\data.csv")
investing_url<-"http://profit.ndtv.com/market/stocks-losers/nifty_daily"
Losers<-readHTMLTable(investing_url)
Losers<- as.data.frame(Losers)
Losers<- Losers[,colnames(Losers)%in% c("common.table.Company","common.table.Change..")]
Losers<- Losers[-1,]
colnames(Losers)<- gsub("common.table.","",colnames(Losers))
name<-paste("CNX Top Loser's",Sys.Date(),sep = "-")
name<- paste(name,".csv",sep = "")
Losers<-readHTMLTable(investing_url)
library(htmltools)
library(DT)
investing_url<-"http://profit.ndtv.com/market/stocks-losers/nifty_daily"
Losers<-readHTMLTable(investing_url)
library(XML)
readHTMLTable(investing_url)
Losers<-readHTMLTable(investing_url)
Losers<- as.data.frame(Losers)
Losers<- Losers[,colnames(Losers)%in% c("common.table.Company","common.table.Change..")]
Losers<- Losers[-1,]
colnames(Losers)<- gsub("common.table.","",colnames(Losers))
name<-paste("CNX Top Loser's",Sys.Date(),sep = "-")
name<- paste(name,".csv",sep = "")
write.csv(Losers,"C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Weekly Looser\\data.csv")
write.csv(Losers,"C:\\Users\\Vishu\\Documents\\GitHub\\Syllexa\\Syllexa.github.io\\Weekly Looser\\data.csv")
Caledar<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Economic Calendar.R")
Top_Gainer<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Gainer.R")
Top_Loosers<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Losers.R")
Currency<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Currency.R")
Commodity<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Commodities.R")
Market<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Market.R")
Caledar()
Top_Gainer()
Top_Loosers()
Currency()
Commodity()
Market()
Time<- proc.time()
Caledar<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Economic Calendar.R")
Top_Gainer<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Gainer.R")
Top_Loosers<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Losers.R")
Currency<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Currency.R")
Commodity<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Commodities.R")
Market<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Market.R")
Caledar()
rm(list=ls())
Time<- proc.time()
Caledar<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Economic Calendar.R")
Top_Gainer<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Gainer.R")
Top_Loosers<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Losers.R")
Currency<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Currency.R")
Commodity<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Commodities.R")
Market<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Market.R")
Caledar()
Top_Gainer()
Top_Loosers()
Currency()
Commodity()
Market()
proc.time() -Time
rm(list=ls())
Time<- proc.time()
Caledar<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Economic Calendar.R")
Top_Gainer<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Gainer.R")
Top_Loosers<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Losers.R")
Currency<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Currency.R")
Commodity<-dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Commodities.R")
Market<- dget("https://raw.githubusercontent.com/vishukapoor/Syllexa/gh-pages/Syllexa.github.io/R-Scripts/Market.R")
Caledar()
Top_Gainer()
Top_Loosers()
Currency()
Commodity()
Market()
proc.time() -Time
